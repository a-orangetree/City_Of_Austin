{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import re\n",
    "\n",
    "# import pip\n",
    "# pip.main(['install', 'xgboost'])\n",
    "import xgboost as xgb\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing_data = pd.read_csv('data/2014_Housing_Market_Analysis_Data_by_Zip_Code.csv')\n",
    "crime_2016_data = pd.read_csv('data/2016_Annual_Crime_Data.csv')\n",
    "crime_2015_data = pd.read_csv('data/Annual_Crime_Dataset_2015.csv')\n",
    "library_data = pd.read_csv('data/Austin_Public_Library_Locations.csv')\n",
    "water_consumption_data = pd.read_csv('data/Austin_Water_-_Residential_Water_Consumption.csv')\n",
    "campaign_finance_data = pd.read_csv('data/Campaign_Finance_Data_-_Report_Detail_Dataset.csv')\n",
    "park_data = pd.read_csv('data/City_of_Austin_Parks_data.csv')\n",
    "public_art_data = pd.read_csv('data/City_of_Austin_Public_Art_Collection.csv')\n",
    "public_venue_data = pd.read_csv('data/Creative_Workspaces__Performance_Venues__Galleries___Museums.csv')\n",
    "ev_charging_data = pd.read_csv('data/Electric_Vehicle_Charging_Network.csv')\n",
    "restaurant_inspection_data = pd.read_csv('data/Restaurant_Inspection_Scores.csv')\n",
    "traffic_camera_data = pd.read_csv('data/Traffic_Cameras.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Zip Code from Address column in library data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library_data['Zip_Code'] = library_data['Address'].str.findall('\\s+\\d+\\n')\n",
    "library_data['Zip_Code'] = library_data['Zip_Code'].str[0].str[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Restaurant Inspections (Multiple Dates per Restaurant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prashanth/anaconda/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "restaurant_max_inspection = restaurant_inspection_data.groupby('Restaurant Name', as_index = False)['Inspection Date'].agg('max')\n",
    "\n",
    "restaurant_inspection = pd.merge(left = restaurant_max_inspection, right = restaurant_inspection_data\n",
    "                      , how = 'inner'\n",
    "                      , left_on = ['Restaurant Name', 'Inspection Date']\n",
    "                      , right_on = ['Restaurant Name', 'Inspection Date'])\n",
    "\n",
    "restaurant_inspection_data = restaurant_inspection.drop_duplicates()\n",
    "\n",
    "restaurant_inspection_data['Zip Code'] = restaurant_inspection_data['Zip Code'].str[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Files to Zip Code level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crime_2015 = crime_2015_data.groupby('GO Location Zip', as_index = False).size()\n",
    "crime_2015 = crime_2015.reset_index()\n",
    "crime_2015 = crime_2015.rename(columns = {0: 'crimes_2015'})\n",
    "# print(crime_2015.head())\n",
    "\n",
    "crime_2016 = crime_2016_data.groupby('GO Location Zip', as_index = False).size()\n",
    "crime_2016 = crime_2016.reset_index()\n",
    "crime_2016 = crime_2016.rename(columns = {0: 'crimes_2016'})\n",
    "# crime_2016.head()\n",
    "\n",
    "ev_charging = pd.DataFrame(ev_charging_data.groupby('Postal Code', as_index = False).size())\n",
    "ev_charging = ev_charging.reset_index()\n",
    "ev_charging = ev_charging.rename(columns = {0: 'ev_charging_stations'})\n",
    "# ev_charging.head()\n",
    "\n",
    "restaurant_inspection = restaurant_inspection_data.groupby('Zip Code', as_index = False)['Score'].agg(['median','size'])\n",
    "restaurant_inspection = restaurant_inspection.reset_index()\n",
    "restaurant_inspection = restaurant_inspection.rename(columns = {'median': 'median_rest_insp_score', 'size':'number_of_inspections'})\n",
    "restaurant_inspection['Zip Code'] = pd.to_numeric(restaurant_inspection['Zip Code'])\n",
    "# print(restaurant_inspection.head())\n",
    "\n",
    "public_art = public_art_data.groupby('Location Zip Code', as_index = False).size()\n",
    "public_art = public_art.reset_index()\n",
    "public_art = public_art.rename(columns = {0: 'public_art_installations'})\n",
    "# public_art.head()\n",
    "\n",
    "public_venue = public_venue_data.groupby('ZIP', as_index = False).size()\n",
    "public_venue = public_venue.reset_index()\n",
    "public_venue = public_venue.rename(columns = {0: 'public_venues'})\n",
    "# public_venue.head()\n",
    "\n",
    "park = park_data.groupby('ZIP_CODE', as_index = False).size()\n",
    "park = park.reset_index()\n",
    "park = park.rename(columns = {0: 'parks'})\n",
    "# park.head()\n",
    "\n",
    "water_consumption = water_consumption_data.groupby('Postal Code', as_index = False)['Total Gallons'].median()\n",
    "water_consumption = water_consumption.reset_index()\n",
    "water_consumption = water_consumption.rename(columns = {'Total Gallons': 'median_water_used_gal'})\n",
    "del water_consumption['index']\n",
    "# water_consumption.head()\n",
    "\n",
    "library = library_data.groupby('Zip_Code', as_index = False).size()\n",
    "library = library.reset_index()\n",
    "library = library.rename(columns = {0: 'libraries'})\n",
    "library['Zip_Code'] = pd.to_numeric(library['Zip_Code'].str.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47, 2)\n"
     ]
    }
   ],
   "source": [
    "combined_data = crime_2015.copy()\n",
    "# print(crime_2015.shape)\n",
    "print(combined_data.shape)\n",
    "\n",
    "combined_data = pd.merge(left = combined_data, right = crime_2016\n",
    "                      , how = 'inner'\n",
    "                      , on = 'GO Location Zip')\n",
    "# print(combined_data.shape)\n",
    "\n",
    "combined_data = pd.merge(left = combined_data, right = ev_charging\n",
    "                      , how = 'left'\n",
    "                      , left_on = 'GO Location Zip'\n",
    "                      , right_on = 'Postal Code')\n",
    "del combined_data['Postal Code']\n",
    "# print(combined_data.shape)\n",
    "\n",
    "combined_data = pd.merge(left = combined_data, right = housing_data\n",
    "                      , how = 'inner'\n",
    "                      , left_on = 'GO Location Zip'\n",
    "                      , right_on = 'Zip Code')\n",
    "del combined_data['Zip Code']\n",
    "# print(combined_data.shape)\n",
    "\n",
    "combined_data = pd.merge(left = combined_data, right = park\n",
    "                      , how = 'left'\n",
    "                      , left_on = 'GO Location Zip'\n",
    "                      , right_on = 'ZIP_CODE')\n",
    "del combined_data['ZIP_CODE']\n",
    "# print(combined_data.shape)\n",
    "\n",
    "combined_data = pd.merge(left = combined_data, right = public_art\n",
    "                      , how = 'left'\n",
    "                      , left_on = 'GO Location Zip'\n",
    "                      , right_on = 'Location Zip Code')\n",
    "del combined_data['Location Zip Code']\n",
    "# print(combined_data.shape)\n",
    "\n",
    "combined_data = pd.merge(left = combined_data, right = water_consumption\n",
    "                      , how = 'left'\n",
    "                      , left_on = 'GO Location Zip'\n",
    "                      , right_on = 'Postal Code')\n",
    "del combined_data['Postal Code']\n",
    "# print(combined_data.shape)\n",
    "\n",
    "combined_data = pd.merge(left = combined_data, right = library\n",
    "                      , how = 'left'\n",
    "                      , left_on = 'GO Location Zip'\n",
    "                      , right_on = 'Zip_Code')\n",
    "del combined_data['Zip_Code']\n",
    "# print(combined_data.shape)\n",
    "# print(combined_data)\n",
    "\n",
    "data_study = pd.DataFrame(combined_data)\n",
    "data_study\n",
    "data_study.to_csv(\"study.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove String Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data['Population below poverty level'] = pd.to_numeric(combined_data['Population below poverty level'].str.replace('\\%', ''))\n",
    "combined_data['Median household income'] = pd.to_numeric(combined_data['Median household income'].str.replace('\\$', ''))\n",
    "combined_data['Non-White, Non-Hispanic or Latino'] = pd.to_numeric(combined_data['Non-White, Non-Hispanic or Latino'].str.replace('\\%', ''))\n",
    "combined_data['Hispanic or Latino, of any race'] = pd.to_numeric(combined_data['Hispanic or Latino, of any race'].str.replace('\\%', ''))\n",
    "combined_data['Population with disability'] = pd.to_numeric(combined_data['Population with disability'].str.replace('\\%', ''))\n",
    "combined_data['Unemployment'] = pd.to_numeric(combined_data['Unemployment'].str.replace('\\%', ''))\n",
    "combined_data['Change in percentage of population below poverty, 2000-2012'] = pd.to_numeric(combined_data['Change in percentage of population below poverty, 2000-2012'].str.replace('\\%', ''))\n",
    "combined_data['Change in median rent, 2000-2012'] = pd.to_numeric(combined_data['Change in median rent, 2000-2012'].str.replace('\\%', ''))\n",
    "combined_data['Change in median home value, 2000-2012'] = pd.to_numeric(combined_data['Change in median home value, 2000-2012'].str.replace('\\%', ''))\n",
    "combined_data['Percentage of homes within 1/4-mi of transit stop'] = pd.to_numeric(combined_data['Percentage of homes within 1/4-mi of transit stop'].str.replace('\\%', ''))\n",
    "combined_data['Average monthly transportation cost'] = pd.to_numeric(combined_data['Average monthly transportation cost'].str.replace('\\$', ''))\n",
    "combined_data['Percentage of housing and transportation costs that is transportation-related'] = pd.to_numeric(combined_data['Percentage of housing and transportation costs that is transportation-related'].str.replace('\\%', ''))\n",
    "combined_data['Large households (5+ members)'] = pd.to_numeric(combined_data['Large households (5+ members)'].str.replace('\\%', ''))\n",
    "combined_data['Homes affordable to people earning less than $50,000'] = pd.to_numeric(combined_data['Homes affordable to people earning less than $50,000'].str.replace('\\%', ''))\n",
    "combined_data['Rentals affordable to people earning less than $25,000'] = pd.to_numeric(combined_data['Rentals affordable to people earning less than $25,000'].str.replace('\\%', ''))\n",
    "combined_data['Rent-restricted units'] = pd.to_numeric(combined_data['Rent-restricted units'].str.replace('\\%', ''))\n",
    "combined_data['Median rent'] = pd.to_numeric(combined_data['Median rent'].str.replace('\\$', ''))\n",
    "combined_data['Median home value'] = pd.to_numeric(combined_data['Median home value'].str.replace('\\$', ''))\n",
    "combined_data['Percentage of rental units in poor condition'] = pd.to_numeric(combined_data['Percentage of rental units in poor condition'].str.replace('\\%', ''))\n",
    "combined_data['Housing Choice Voucher holders'] = pd.to_numeric(combined_data['Housing Choice Voucher holders'].str.replace('\\%', ''))\n",
    "combined_data['Percent change in number of housing units, 2000-2012'] = pd.to_numeric(combined_data['Percent change in number of housing units, 2000-2012'].str.replace('\\%', ''))\n",
    "combined_data['Owner units affordable to average retail/service worker'] = pd.to_numeric(combined_data['Owner units affordable to average retail/service worker'].str.replace('\\%', ''))\n",
    "combined_data['Rental units affordable to average retail/service worker'] = pd.to_numeric(combined_data['Rental units affordable to average retail/service worker'].str.replace('\\%', ''))\n",
    "combined_data['Rental units affordable to average artist'] = pd.to_numeric(combined_data['Rental units affordable to average artist'].str.replace('\\%', ''))\n",
    "combined_data['Owner units affordable to average artist'] = pd.to_numeric(combined_data['Owner units affordable to average artist'].str.replace('\\%', ''))\n",
    "combined_data['Rental units affordable to average teacher'] = pd.to_numeric(combined_data['Rental units affordable to average teacher'].str.replace('\\%', ''))\n",
    "combined_data['Owner units affordable to average teacher'] = pd.to_numeric(combined_data['Owner units affordable to average teacher'].str.replace('\\%', ''))\n",
    "combined_data['Rental units affordable to average tech worker'] = pd.to_numeric(combined_data['Rental units affordable to average tech worker'].str.replace('\\%', ''))\n",
    "combined_data['Owner units affordable to average tech worker'] = pd.to_numeric(combined_data['Owner units affordable to average tech worker'].str.replace('\\%', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def forward_selected(data, response):\n",
    "#     \"\"\"Linear model designed by forward selection.\n",
    "\n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     data : pandas DataFrame with all possible predictors and response\n",
    "\n",
    "#     response: string, name of response column in data\n",
    "\n",
    "#     Returns:\n",
    "#     --------\n",
    "#     model: an \"optimal\" fitted statsmodels linear model\n",
    "#            with an intercept\n",
    "#            selected by forward selection\n",
    "#            evaluated by adjusted R-squared\n",
    "#     \"\"\"\n",
    "#     remaining = set(data.columns)\n",
    "#     remaining.remove(response)\n",
    "#     selected = []\n",
    "#     current_score, best_new_score = 0.0, 0.0\n",
    "#     while remaining and current_score == best_new_score:\n",
    "#         scores_with_candidates = []\n",
    "#         for candidate in remaining:\n",
    "#             formula = \"{} ~ {} + 1\".format(response,\n",
    "#                                            ' + '.join(selected + [candidate]))\n",
    "#             score = smf.ols(formula, data).fit().rsquared_adj\n",
    "#             scores_with_candidates.append((score, candidate))\n",
    "#         scores_with_candidates.sort()\n",
    "#         best_new_score, best_candidate = scores_with_candidates.pop()\n",
    "#         if current_score < best_new_score:\n",
    "#             remaining.remove(best_candidate)\n",
    "#             selected.append(best_candidate)\n",
    "#             current_score = best_new_score\n",
    "#     formula = \"{} ~ {} + 1\".format(response,\n",
    "#                                    ' + '.join(selected))\n",
    "#     model = smf.ols(formula, data).fit()\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = forward_selected(combined_data,'')\n",
    "\n",
    "# print (model.model.formula)\n",
    "# # sl ~ rk + yr + 1\n",
    "\n",
    "# print (model.rsquared_adj)\n",
    "# # 0.835190760538"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = combined_data\n",
    "# X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "# y = data.target\n",
    "\n",
    "\n",
    "# def stepwise_selection(X, y, \n",
    "#                        initial_list=[], \n",
    "#                        threshold_in=0.01, \n",
    "#                        threshold_out = 0.05, \n",
    "#                        verbose=True):\n",
    "#     \"\"\" Perform a forward-backward feature selection \n",
    "#     based on p-value from statsmodels.api.OLS\n",
    "#     Arguments:\n",
    "#         X - pandas.DataFrame with candidate features\n",
    "#         y - list-like with the target\n",
    "#         initial_list - list of features to start with (column names of X)\n",
    "#         threshold_in - include a feature if its p-value < threshold_in\n",
    "#         threshold_out - exclude a feature if its p-value > threshold_out\n",
    "#         verbose - whether to print the sequence of inclusions and exclusions\n",
    "#     Returns: list of selected features \n",
    "#     Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "#     See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "#     \"\"\"\n",
    "#     included = list(initial_list)\n",
    "#     while True:\n",
    "#         changed=False\n",
    "#         # forward step\n",
    "#         excluded = list(set(X.columns)-set(included))\n",
    "#         new_pval = pd.Series(index=excluded)\n",
    "#         for new_column in excluded:\n",
    "#             model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "#             new_pval[new_column] = model.pvalues[new_column]\n",
    "#         best_pval = new_pval.min()\n",
    "#         if best_pval < threshold_in:\n",
    "#             best_feature = new_pval.argmin()\n",
    "#             included.append(best_feature)\n",
    "#             changed=True\n",
    "#             if verbose:\n",
    "#                 print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "#         # backward step\n",
    "#         model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "#         # use all coefs except intercept\n",
    "#         pvalues = model.pvalues.iloc[1:]\n",
    "#         worst_pval = pvalues.max() # null if pvalues is empty\n",
    "#         if worst_pval > threshold_out:\n",
    "#             changed=True\n",
    "#             worst_feature = pvalues.argmax()\n",
    "#             included.remove(worst_feature)\n",
    "#             if verbose:\n",
    "#                 print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "#         if not changed:\n",
    "#             break\n",
    "#     return included\n",
    "\n",
    "# result = stepwise_selection(X, y)\n",
    "\n",
    "# print('resulting features:')\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
